# OPSEC Review Script â€“ Usage Guide

This document explains how to use the `opsec_review.py` script to analyze DNS activity and generate OPSEC-oriented reports in a safe, reproducible, and auditable way.

---

## ğŸ“Œ Purpose

The script is designed to:

- Analyze real DNS query logs
- Classify domains by category (telemetry, ads, essential, unknown)
- Detect noise, tracking-heavy roots, and phantom patterns
- Generate a human-readable OPSEC report
- Keep raw data out of version control

---

## ğŸ“ Required Directory Structure

The script expects the following structure:

# OPSEC Review Script â€“ Usage Guide

This document explains how to use the `opsec_review.py` script to analyze DNS activity and generate OPSEC-oriented reports in a safe, reproducible, and auditable way.

---

## ğŸ“Œ Purpose

The script is designed to:

- Analyze real DNS query logs
- Classify domains by category (telemetry, ads, essential, unknown)
- Detect noise, tracking-heavy roots, and phantom patterns
- Generate a human-readable OPSEC report
- Keep raw data out of version control

---

## ğŸ“ Required Directory Structure

The script expects the following structure:
```
opsec/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ dns_queries.txt # Raw DNS domains (one per line)
â”‚
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ opsec_review.py # Analysis script
â”‚
â”œâ”€â”€ reports/
â”‚ â””â”€â”€ .gitkeep # Reports are generated here (not versioned)
opsec/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ dns_queries.txt # Raw DNS domains (one per line)
â”‚
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ opsec_review.py # Analysis script
â”‚
â”œâ”€â”€ reports/
â”‚ â””â”€â”€ .gitkeep # Reports are generated here (not versioned)
```

Resultado en GitHub

- AlineaciÃ³n perfecta

- TipografÃ­a monoespaciada

- Lectura inmediata

- EstÃ¡ndar profesional (README / docs tÃ©cnicos)


> âš ï¸ `opsec/data/` and `opsec/reports/` are intentionally excluded from Git.

---

## ğŸ“¥ Input Format

The script requires a plain text file:

- `opsec/data/dns_queries.txt`


### Format rules

- One domain per line  
- No headers  
- No timestamps  
- Duplicates are allowed (used for frequency analysis)

Example:

- `example.com`
- `api.example.com`
- `tracker.vendor.net`


---

## ğŸ”„ Preparing the DNS Input

If you export DNS logs from **NextDNS** as CSV:

```bash
cut -d',' -f2 nextdns-export.csv | tail -n +2 > opsec/data/dns_queries.txt

Verify the result:
- `head opsec/data/dns_queries.txt`

ğŸ§ª Environment Setup (Recommended)

Use an isolated Python environment.

Option A â€“ Conda
- `conda create -n opsec-review python=3.11`
- `conda activate opsec-review`

Option B â€“ Virtualenv
- `python3 -m venv venv`
- `source venv/bin/activate`
No external dependencies are required.

â–¶ï¸ Running the Script

From the repository root:
- `python opsec/scripts/opsec_review.py`

ğŸ“„ Output

The script generates a Markdown report:
- `opsec/reports/opsec-report.md`

The report includes

- Execution timestamp (UTC)

- Total DNS queries analyzed

- Top recurring domains

- Known telemetry / tracking roots

- Unknown or low-frequency domains

- OPSEC interpretation notes

âš ï¸ Reports are not committed to Git by design.

ğŸ” Recommended Usage Cycle

- After major OS updates

- After installing new applications

- Monthly as part of OPSEC hygiene

- Compare reports over time (manually or externally)

ğŸ›‘ OPSEC Notes

- Never commit raw DNS logs

- Never commit generated reports

- Treat DNS data as sensitive metadata

- Review unexpected domains before allowing or blocking

âœ… Success Criteria

- A healthy baseline typically shows:

- High volume from known system roots

- Limited ad / telemetry domains

- Stable domain patterns over time

- No unexplained spikes or unknown TLDs

ğŸ§  Final Principle

Measure first. Block second. Document always.

OPSEC is a process, not a static configuration.



